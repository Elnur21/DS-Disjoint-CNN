{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (575, 9, 144)\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets import load_classification\n",
    "X, y = load_classification(\"ArticularyWordRecognition\")\n",
    "print(\" Shape of X = \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_classification(\"ArticularyWordRecognition\",  split=\"train\")\n",
    "X_test, y_test = load_classification(\"ArticularyWordRecognition\",  split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Main] Problem: NATOPS\n",
      "[Main] All labels: ['1.0' '10.0' '11.0' '12.0' '13.0' '14.0' '15.0' '16.0' '17.0' '18.0'\n",
      " '19.0' '2.0' '20.0' '21.0' '22.0' '23.0' '24.0' '25.0' '3.0' '4.0' '5.0'\n",
      " '6.0' '7.0' '8.0' '9.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_985966/3900600103.py:153: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  val_index = np.random.randint(0, np.int(x_train.shape[0]), np.int(x_train.shape[0] / 10), dtype=int)\n",
      "2024-03-18 11:22:55.716269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 11:22:56.658420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DisJoint DCNN_2L Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 11:22:57.472369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.511458: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.511731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.513518: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.513804: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.514000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.571566: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.571767: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.571958: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 11:22:57.572516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,625</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu (\u001b[38;5;33mELU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m589,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_1 (\u001b[38;5;33mELU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_2 (\u001b[38;5;33mELU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m262,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ elu_3 (\u001b[38;5;33mELU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,625\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">855,705</span> (3.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m855,705\u001b[0m (3.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">855,193</span> (3.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m855,193\u001b[0m (3.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DCNN_2L] Training DCNN_2L Classifier\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710757379.727096  987614 service.cc:145] XLA service 0x7f36f8005000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1710757379.727119  987614 service.cc:153]   StreamExecutor device (0): Quadro P400, Compute Capability 6.1\n",
      "2024-03-18 11:22:59.810803: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-18 11:23:00.089693: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1861 - loss: 12.5642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1710757385.063903  987614 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.3204 - loss: 10.6618 - val_accuracy: 0.7037 - val_loss: 0.7593 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8532 - loss: 3.6723 - val_accuracy: 0.9630 - val_loss: 0.0739 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9846 - loss: 1.9103 - val_accuracy: 0.9630 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9961 - loss: 0.9084 - val_accuracy: 1.0000 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.5276 - val_accuracy: 1.0000 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.2981 - val_accuracy: 1.0000 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.2688 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.1638 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.1102 - val_accuracy: 1.0000 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0953 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0771 - val_accuracy: 1.0000 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0620 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.1063 - val_accuracy: 1.0000 - val_loss: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0032 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0028 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0020 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.1163 - val_accuracy: 1.0000 - val_loss: 0.0032 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 0.2285 - val_accuracy: 1.0000 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9978 - loss: 0.2863 - val_accuracy: 1.0000 - val_loss: 0.0028 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1204 - val_accuracy: 1.0000 - val_loss: 8.1452e-04 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 9.5774e-04 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 8.0012e-04 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 7.5511e-04 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 8.1876e-04 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 6.2854e-04 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 5.8710e-04 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 5.4658e-04 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 5.1393e-04 - learning_rate: 0.0010\n",
      "Epoch 34/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 4.6916e-04 - learning_rate: 0.0010\n",
      "Epoch 35/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 3.9131e-04 - learning_rate: 0.0010\n",
      "Epoch 36/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 3.6876e-04 - learning_rate: 0.0010\n",
      "Epoch 37/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 3.3775e-04 - learning_rate: 0.0010\n",
      "Epoch 38/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 3.1824e-04 - learning_rate: 0.0010\n",
      "Epoch 39/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 2.8991e-04 - learning_rate: 0.0010\n",
      "Epoch 40/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.7706e-04 - learning_rate: 0.0010\n",
      "Epoch 41/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.6093e-04 - learning_rate: 0.0010\n",
      "Epoch 42/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 2.3496e-04 - learning_rate: 0.0010\n",
      "Epoch 43/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 2.1901e-04 - learning_rate: 0.0010\n",
      "Epoch 44/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.0804e-04 - learning_rate: 0.0010\n",
      "Epoch 45/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.0920e-04 - learning_rate: 0.0010\n",
      "Epoch 46/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 2.0447e-04 - learning_rate: 0.0010\n",
      "Epoch 47/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.8596e-04 - learning_rate: 0.0010\n",
      "Epoch 48/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.7666e-04 - learning_rate: 0.0010\n",
      "Epoch 49/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.6435e-04 - learning_rate: 0.0010\n",
      "Epoch 50/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.6471e-04 - learning_rate: 0.0010\n",
      "Epoch 51/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 1.5172e-04 - learning_rate: 0.0010\n",
      "Epoch 52/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.4887e-04 - learning_rate: 0.0010\n",
      "Epoch 53/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 3.5101e-04 - learning_rate: 0.0010\n",
      "Epoch 54/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.2901 - val_accuracy: 1.0000 - val_loss: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 55/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.9222 - val_accuracy: 1.0000 - val_loss: 2.0124e-04 - learning_rate: 0.0010\n",
      "Epoch 56/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.2050 - val_accuracy: 1.0000 - val_loss: 9.3793e-04 - learning_rate: 0.0010\n",
      "Epoch 57/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 0.0644 - val_accuracy: 1.0000 - val_loss: 2.4446e-04 - learning_rate: 0.0010\n",
      "Epoch 58/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 2.6571e-04 - learning_rate: 0.0010\n",
      "Epoch 59/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0289 - val_accuracy: 1.0000 - val_loss: 4.0982e-04 - learning_rate: 0.0010\n",
      "Epoch 60/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 4.5701e-04 - learning_rate: 0.0010\n",
      "Epoch 61/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 4.8389e-04 - learning_rate: 0.0010\n",
      "Epoch 62/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 4.6985e-04 - learning_rate: 0.0010\n",
      "Epoch 63/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 4.7671e-04 - learning_rate: 0.0010\n",
      "Epoch 64/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 3.7337e-04 - learning_rate: 0.0010\n",
      "Epoch 65/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 3.5317e-04 - learning_rate: 0.0010\n",
      "Epoch 66/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 3.1658e-04 - learning_rate: 0.0010\n",
      "Epoch 67/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 2.8666e-04 - learning_rate: 0.0010\n",
      "Epoch 68/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.6749e-04 - learning_rate: 0.0010\n",
      "Epoch 69/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.6958e-04 - learning_rate: 0.0010\n",
      "Epoch 70/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.5343e-04 - learning_rate: 0.0010\n",
      "Epoch 71/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.2651e-04 - learning_rate: 0.0010\n",
      "Epoch 72/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.0901e-04 - learning_rate: 0.0010\n",
      "Epoch 73/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 3.1519e-04 - learning_rate: 0.0010\n",
      "Epoch 74/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 2.6632e-04 - learning_rate: 0.0010\n",
      "Epoch 75/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 2.3926e-04 - learning_rate: 0.0010\n",
      "Epoch 76/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.1233e-04 - learning_rate: 0.0010\n",
      "Epoch 77/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.8895e-04 - learning_rate: 0.0010\n",
      "Epoch 78/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.8095e-04 - learning_rate: 0.0010\n",
      "Epoch 79/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.6828e-04 - learning_rate: 0.0010\n",
      "Epoch 80/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.5904e-04 - learning_rate: 0.0010\n",
      "Epoch 81/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.5138e-04 - learning_rate: 0.0010\n",
      "Epoch 82/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 1.3692e-04 - learning_rate: 0.0010\n",
      "Epoch 83/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.2937e-04 - learning_rate: 0.0010\n",
      "Epoch 84/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.1884e-04 - learning_rate: 0.0010\n",
      "Epoch 85/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.0784e-04 - learning_rate: 0.0010\n",
      "Epoch 86/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.0377e-04 - learning_rate: 0.0010\n",
      "Epoch 87/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 9.8884e-05 - learning_rate: 0.0010\n",
      "Epoch 88/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 9.5329e-05 - learning_rate: 0.0010\n",
      "Epoch 89/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 8.6169e-05 - learning_rate: 0.0010\n",
      "Epoch 90/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 1.2918e-04 - learning_rate: 0.0010\n",
      "Epoch 91/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.1286e-04 - learning_rate: 0.0010\n",
      "Epoch 92/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 9.9303e-05 - learning_rate: 0.0010\n",
      "Epoch 93/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 8.9053e-05 - learning_rate: 0.0010\n",
      "Epoch 94/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 1.5805e-04 - learning_rate: 0.0010\n",
      "Epoch 95/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.1927 - val_accuracy: 1.0000 - val_loss: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 96/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0502 - val_accuracy: 1.0000 - val_loss: 4.0262e-04 - learning_rate: 0.0010\n",
      "Epoch 97/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 2.9446e-04 - learning_rate: 0.0010\n",
      "Epoch 98/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0327 - val_accuracy: 1.0000 - val_loss: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 1.0000 - val_loss: 8.3796e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 5.6129e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 4.3380e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 3.4435e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 3.0862e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.7047e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.5026e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.2575e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 2.2714e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.0190e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.8055e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 3.4586e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 111/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 1.9161e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 112/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 7.0935e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 113/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 4.1515e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 3.3319e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 2.6950e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 2.0855e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 1.9657e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.6613e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.5054e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.3159e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.1841e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.0426e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 8.9990e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 124/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 8.6116e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 125/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 7.9524e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 126/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 7.4432e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 127/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 7.2171e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 128/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 6.7977e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 129/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 6.0690e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 130/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 6.0699e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 131/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 5.8224e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 132/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 5.2650e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 133/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.1867e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 134/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 6.1571e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 135/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 5.7506e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 136/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 5.5169e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 137/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 5.0530e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 138/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.6604e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 139/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 7.7466e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 140/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 7.6792e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 141/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 7.5363e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 142/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 7.1757e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 143/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 6.0930e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 144/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 5.6114e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 145/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.5366e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 146/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 6.8138e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 147/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 5.8626e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 148/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 5.0884e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 149/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.6130e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 150/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 4.3196e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 151/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.9372e-04 - val_accuracy: 1.0000 - val_loss: 3.9155e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 152/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.3173e-04 - val_accuracy: 1.0000 - val_loss: 3.6246e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 153/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 3.4607e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 154/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.3611e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 155/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.4335e-04 - val_accuracy: 1.0000 - val_loss: 3.1720e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 156/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.9702e-04 - val_accuracy: 1.0000 - val_loss: 3.0928e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 157/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.4134e-04 - val_accuracy: 1.0000 - val_loss: 2.9204e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 158/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.7481e-04 - val_accuracy: 1.0000 - val_loss: 2.7959e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 159/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.4212e-04 - val_accuracy: 1.0000 - val_loss: 2.6982e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 160/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.5320e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 161/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.9605e-04 - val_accuracy: 1.0000 - val_loss: 2.3633e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 162/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.8171e-04 - val_accuracy: 1.0000 - val_loss: 2.2670e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 163/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.6481e-04 - val_accuracy: 1.0000 - val_loss: 2.1728e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 164/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.9517e-04 - val_accuracy: 1.0000 - val_loss: 2.3112e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 165/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.3028e-04 - val_accuracy: 1.0000 - val_loss: 2.2210e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 166/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.6591e-04 - val_accuracy: 1.0000 - val_loss: 2.1205e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 167/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.3003e-04 - val_accuracy: 1.0000 - val_loss: 2.4029e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 168/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.3656e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 169/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.3515e-04 - val_accuracy: 1.0000 - val_loss: 2.2915e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 170/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.8632e-04 - val_accuracy: 1.0000 - val_loss: 2.5164e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 171/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.1092e-04 - val_accuracy: 1.0000 - val_loss: 2.3615e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 172/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.4284e-04 - val_accuracy: 1.0000 - val_loss: 2.1522e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 173/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.5123e-04 - val_accuracy: 1.0000 - val_loss: 2.0507e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 174/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.9429e-04 - val_accuracy: 1.0000 - val_loss: 1.9528e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 175/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.7435e-04 - val_accuracy: 1.0000 - val_loss: 1.8362e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 176/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.8248e-04 - val_accuracy: 1.0000 - val_loss: 1.8096e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 177/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.9948e-04 - val_accuracy: 1.0000 - val_loss: 1.7656e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 178/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.6282e-04 - val_accuracy: 1.0000 - val_loss: 1.7366e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 179/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.1502e-04 - val_accuracy: 1.0000 - val_loss: 1.6459e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 180/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.7384e-04 - val_accuracy: 1.0000 - val_loss: 1.6063e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 181/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.5354e-04 - val_accuracy: 1.0000 - val_loss: 1.5536e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 182/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.3543e-04 - val_accuracy: 1.0000 - val_loss: 1.5516e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 183/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.0543e-04 - val_accuracy: 1.0000 - val_loss: 1.5311e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 184/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.9188e-04 - val_accuracy: 1.0000 - val_loss: 1.4799e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 185/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.0578e-04 - val_accuracy: 1.0000 - val_loss: 1.4635e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 186/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.8669e-04 - val_accuracy: 1.0000 - val_loss: 1.4556e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 187/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.6587e-04 - val_accuracy: 1.0000 - val_loss: 1.4160e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 188/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.0768e-04 - val_accuracy: 1.0000 - val_loss: 1.3752e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 189/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.7915e-04 - val_accuracy: 1.0000 - val_loss: 1.3626e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 190/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.0901e-04 - val_accuracy: 1.0000 - val_loss: 1.3293e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 191/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2371e-04 - val_accuracy: 1.0000 - val_loss: 1.3007e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 192/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.1604e-04 - val_accuracy: 1.0000 - val_loss: 1.2627e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 193/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.8352e-04 - val_accuracy: 1.0000 - val_loss: 1.2393e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 194/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.0663e-04 - val_accuracy: 1.0000 - val_loss: 1.2851e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 195/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.9889e-04 - val_accuracy: 1.0000 - val_loss: 1.2706e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 196/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.0204e-04 - val_accuracy: 1.0000 - val_loss: 1.2446e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 197/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.7351e-04 - val_accuracy: 1.0000 - val_loss: 1.2281e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 198/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.6910e-04 - val_accuracy: 1.0000 - val_loss: 2.5743e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 199/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 5.4728e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 200/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 3.7308e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 201/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.3678e-04 - val_accuracy: 1.0000 - val_loss: 3.3620e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 202/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.9322e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 203/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.7972e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 204/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.5220e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 205/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.3612e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 206/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.0061e-04 - val_accuracy: 1.0000 - val_loss: 2.1961e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 207/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.6443e-04 - val_accuracy: 1.0000 - val_loss: 2.0971e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 208/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.0858e-04 - val_accuracy: 1.0000 - val_loss: 2.0168e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 209/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.5261e-04 - val_accuracy: 1.0000 - val_loss: 1.8935e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 210/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.0098e-04 - val_accuracy: 1.0000 - val_loss: 1.7820e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 211/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.2632e-04 - val_accuracy: 1.0000 - val_loss: 1.6123e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 212/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.8798e-04 - val_accuracy: 1.0000 - val_loss: 1.5573e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 213/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.4766e-04 - val_accuracy: 1.0000 - val_loss: 1.4949e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 214/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.2014e-04 - val_accuracy: 1.0000 - val_loss: 1.4320e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 215/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.1709e-04 - val_accuracy: 1.0000 - val_loss: 1.3535e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 216/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.8207e-04 - val_accuracy: 1.0000 - val_loss: 1.2807e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 217/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.7780e-04 - val_accuracy: 1.0000 - val_loss: 1.2476e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 218/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.7089e-04 - val_accuracy: 1.0000 - val_loss: 1.2003e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 219/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3686e-04 - val_accuracy: 1.0000 - val_loss: 1.1900e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 220/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.3330e-04 - val_accuracy: 1.0000 - val_loss: 1.1192e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 221/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.4877e-04 - val_accuracy: 1.0000 - val_loss: 1.0935e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 222/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3300e-04 - val_accuracy: 1.0000 - val_loss: 1.0647e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 223/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.3040e-04 - val_accuracy: 1.0000 - val_loss: 1.0287e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 224/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.4122e-04 - val_accuracy: 1.0000 - val_loss: 1.0177e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 225/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.4940e-04 - val_accuracy: 1.0000 - val_loss: 4.5851e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 226/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 3.8329e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 227/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.2914e-04 - val_accuracy: 1.0000 - val_loss: 3.6181e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 228/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.7384e-04 - val_accuracy: 1.0000 - val_loss: 3.1954e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 229/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 2.8570e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 230/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.1491e-04 - val_accuracy: 1.0000 - val_loss: 2.5724e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 231/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.9052e-04 - val_accuracy: 1.0000 - val_loss: 2.2018e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 232/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.5991e-04 - val_accuracy: 1.0000 - val_loss: 2.0504e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 233/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.8412e-04 - val_accuracy: 1.0000 - val_loss: 1.9427e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 234/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.5203e-04 - val_accuracy: 1.0000 - val_loss: 1.8154e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 235/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.8742e-04 - val_accuracy: 1.0000 - val_loss: 1.7250e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 236/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.8665e-04 - val_accuracy: 1.0000 - val_loss: 1.6186e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 237/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.7339e-04 - val_accuracy: 1.0000 - val_loss: 1.7127e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 238/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.1790e-04 - val_accuracy: 1.0000 - val_loss: 1.6139e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 239/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.7016e-04 - val_accuracy: 1.0000 - val_loss: 1.5290e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 240/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.3668e-04 - val_accuracy: 1.0000 - val_loss: 1.4412e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 241/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.9410e-04 - val_accuracy: 1.0000 - val_loss: 1.3793e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 242/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.2140e-04 - val_accuracy: 1.0000 - val_loss: 1.2943e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 243/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.3511e-04 - val_accuracy: 1.0000 - val_loss: 1.3435e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 244/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.1666e-04 - val_accuracy: 1.0000 - val_loss: 1.3143e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 245/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.2063e-04 - val_accuracy: 1.0000 - val_loss: 1.2575e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 246/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.7819e-04 - val_accuracy: 1.0000 - val_loss: 1.1725e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 247/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.3828e-04 - val_accuracy: 1.0000 - val_loss: 1.1634e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 248/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.9436e-04 - val_accuracy: 1.0000 - val_loss: 1.6456e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 249/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 1.5414e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 250/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.6363e-04 - val_accuracy: 1.0000 - val_loss: 1.3967e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 251/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.2184e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 252/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.0346e-04 - val_accuracy: 1.0000 - val_loss: 1.1894e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 253/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8637e-04 - val_accuracy: 1.0000 - val_loss: 1.1183e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 254/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.1739e-04 - val_accuracy: 1.0000 - val_loss: 1.0889e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 255/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.0774e-04 - val_accuracy: 1.0000 - val_loss: 1.0600e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 256/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.0087e-04 - val_accuracy: 1.0000 - val_loss: 1.0284e-05 - learning_rate: 1.2500e-04\n",
      "Epoch 257/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.1339e-04 - val_accuracy: 1.0000 - val_loss: 9.7664e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 258/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1876e-04 - val_accuracy: 1.0000 - val_loss: 9.6571e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 259/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.3714e-04 - val_accuracy: 1.0000 - val_loss: 9.0847e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 260/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.4557e-04 - val_accuracy: 1.0000 - val_loss: 8.9605e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 261/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.1467e-04 - val_accuracy: 1.0000 - val_loss: 8.6153e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 262/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.8006e-04 - val_accuracy: 1.0000 - val_loss: 8.4377e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 263/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.6012e-04 - val_accuracy: 1.0000 - val_loss: 8.3384e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 264/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.7854e-04 - val_accuracy: 1.0000 - val_loss: 8.0044e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 265/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.0291e-04 - val_accuracy: 1.0000 - val_loss: 7.9845e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 266/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.8058e-04 - val_accuracy: 1.0000 - val_loss: 7.6616e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 267/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.5212e-04 - val_accuracy: 1.0000 - val_loss: 7.4617e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 268/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.7265e-04 - val_accuracy: 1.0000 - val_loss: 7.3959e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 269/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.4445e-04 - val_accuracy: 1.0000 - val_loss: 7.1985e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 270/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.2740e-04 - val_accuracy: 1.0000 - val_loss: 7.1873e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 271/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.5882e-04 - val_accuracy: 1.0000 - val_loss: 7.0308e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 272/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1526e-04 - val_accuracy: 1.0000 - val_loss: 6.8619e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 273/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.3415e-04 - val_accuracy: 1.0000 - val_loss: 6.6744e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 274/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.5575e-04 - val_accuracy: 1.0000 - val_loss: 6.4671e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 275/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.7552e-04 - val_accuracy: 1.0000 - val_loss: 6.0685e-06 - learning_rate: 1.2500e-04\n",
      "Epoch 276/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.6857e-04 - val_accuracy: 1.0000 - val_loss: 6.0598e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 277/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8701e-04 - val_accuracy: 1.0000 - val_loss: 6.7837e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 278/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.8969e-04 - val_accuracy: 1.0000 - val_loss: 6.8396e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 279/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7459e-04 - val_accuracy: 1.0000 - val_loss: 6.8309e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 280/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.1487e-04 - val_accuracy: 1.0000 - val_loss: 6.5863e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 281/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8880e-04 - val_accuracy: 1.0000 - val_loss: 6.4609e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 282/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.2800e-04 - val_accuracy: 1.0000 - val_loss: 6.2696e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 283/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.0121e-04 - val_accuracy: 1.0000 - val_loss: 6.1008e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 284/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.1201e-04 - val_accuracy: 1.0000 - val_loss: 6.0362e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 285/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.2311e-04 - val_accuracy: 1.0000 - val_loss: 5.8710e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 286/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6918e-04 - val_accuracy: 1.0000 - val_loss: 5.8934e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 287/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.3581e-04 - val_accuracy: 1.0000 - val_loss: 5.6984e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 288/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.0497e-04 - val_accuracy: 1.0000 - val_loss: 5.6103e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 289/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.8838e-04 - val_accuracy: 1.0000 - val_loss: 5.5084e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 290/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.1514e-04 - val_accuracy: 1.0000 - val_loss: 5.3905e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 291/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.3652e-04 - val_accuracy: 1.0000 - val_loss: 5.3483e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 292/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.4672e-04 - val_accuracy: 1.0000 - val_loss: 5.1856e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 293/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.0464e-04 - val_accuracy: 1.0000 - val_loss: 5.1570e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 294/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.4270e-04 - val_accuracy: 1.0000 - val_loss: 5.0577e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 295/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5685e-04 - val_accuracy: 1.0000 - val_loss: 5.0030e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 296/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.8641e-04 - val_accuracy: 1.0000 - val_loss: 4.8416e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 297/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.2277e-04 - val_accuracy: 1.0000 - val_loss: 4.6367e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 298/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3580e-04 - val_accuracy: 1.0000 - val_loss: 4.6926e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 299/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.7366e-04 - val_accuracy: 1.0000 - val_loss: 4.6119e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 300/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.8892e-04 - val_accuracy: 1.0000 - val_loss: 4.5312e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 301/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.2425e-04 - val_accuracy: 1.0000 - val_loss: 4.3722e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 302/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.5039e-04 - val_accuracy: 1.0000 - val_loss: 4.2145e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 303/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.6445e-04 - val_accuracy: 1.0000 - val_loss: 4.1723e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 304/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.2422e-04 - val_accuracy: 1.0000 - val_loss: 4.1177e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 305/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4401e-04 - val_accuracy: 1.0000 - val_loss: 4.1363e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 306/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.8395e-04 - val_accuracy: 1.0000 - val_loss: 4.0581e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 307/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.2855e-04 - val_accuracy: 1.0000 - val_loss: 4.0196e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 308/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1628e-04 - val_accuracy: 1.0000 - val_loss: 3.9860e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 309/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 2.1437e-04 - val_accuracy: 1.0000 - val_loss: 3.8122e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 310/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2346e-04 - val_accuracy: 1.0000 - val_loss: 3.9339e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 311/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7517e-04 - val_accuracy: 1.0000 - val_loss: 4.0047e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 312/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.6357e-04 - val_accuracy: 1.0000 - val_loss: 3.9811e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 313/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.8974e-04 - val_accuracy: 1.0000 - val_loss: 3.8470e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 314/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9436e-04 - val_accuracy: 1.0000 - val_loss: 4.8205e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 315/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7810e-04 - val_accuracy: 1.0000 - val_loss: 4.8466e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 316/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5218e-04 - val_accuracy: 1.0000 - val_loss: 4.8267e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 317/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2201e-04 - val_accuracy: 1.0000 - val_loss: 4.7323e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 318/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8891e-04 - val_accuracy: 1.0000 - val_loss: 4.5647e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 319/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8585e-04 - val_accuracy: 1.0000 - val_loss: 4.4219e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 320/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6879e-04 - val_accuracy: 1.0000 - val_loss: 4.3735e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 321/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.1095e-04 - val_accuracy: 1.0000 - val_loss: 4.2915e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 322/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4120e-04 - val_accuracy: 1.0000 - val_loss: 4.2406e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 323/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8250e-04 - val_accuracy: 1.0000 - val_loss: 4.0680e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 324/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7596e-04 - val_accuracy: 1.0000 - val_loss: 3.8991e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 325/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.3434e-04 - val_accuracy: 1.0000 - val_loss: 3.7961e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 326/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.4543e-04 - val_accuracy: 1.0000 - val_loss: 3.6619e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 327/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.6099e-04 - val_accuracy: 1.0000 - val_loss: 3.3975e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 328/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.6047e-04 - val_accuracy: 1.0000 - val_loss: 3.2944e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 329/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.3210e-04 - val_accuracy: 1.0000 - val_loss: 3.2348e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 330/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.4800e-04 - val_accuracy: 1.0000 - val_loss: 3.1379e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 331/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.3427e-04 - val_accuracy: 1.0000 - val_loss: 3.0833e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 332/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6965e-04 - val_accuracy: 1.0000 - val_loss: 1.1829e-05 - learning_rate: 1.0000e-04\n",
      "Epoch 333/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.9618e-04 - val_accuracy: 1.0000 - val_loss: 1.0642e-05 - learning_rate: 1.0000e-04\n",
      "Epoch 334/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8226e-04 - val_accuracy: 1.0000 - val_loss: 8.9133e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 335/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.0209e-04 - val_accuracy: 1.0000 - val_loss: 7.4642e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 336/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.9383e-04 - val_accuracy: 1.0000 - val_loss: 6.3143e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 337/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9331e-04 - val_accuracy: 1.0000 - val_loss: 5.9642e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 338/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.5688e-04 - val_accuracy: 1.0000 - val_loss: 5.6003e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 339/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.0744e-04 - val_accuracy: 1.0000 - val_loss: 5.3309e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 340/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.9745e-04 - val_accuracy: 1.0000 - val_loss: 4.9795e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 341/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.3011e-04 - val_accuracy: 1.0000 - val_loss: 4.6777e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 342/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.9840e-04 - val_accuracy: 1.0000 - val_loss: 4.5883e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 343/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.5315e-04 - val_accuracy: 1.0000 - val_loss: 4.2083e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 344/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.6454e-04 - val_accuracy: 1.0000 - val_loss: 3.9774e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 345/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9292e-04 - val_accuracy: 1.0000 - val_loss: 3.8271e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 346/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5294e-04 - val_accuracy: 1.0000 - val_loss: 3.6632e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 347/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7486e-04 - val_accuracy: 1.0000 - val_loss: 3.6433e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 348/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2790e-04 - val_accuracy: 1.0000 - val_loss: 3.5626e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 349/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.7009e-04 - val_accuracy: 1.0000 - val_loss: 3.4645e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 350/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4248e-04 - val_accuracy: 1.0000 - val_loss: 3.3726e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 351/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.3383e-04 - val_accuracy: 1.0000 - val_loss: 3.2559e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 352/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8593e-04 - val_accuracy: 1.0000 - val_loss: 3.2149e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 353/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.3455e-04 - val_accuracy: 1.0000 - val_loss: 4.2630e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 354/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.7461e-04 - val_accuracy: 1.0000 - val_loss: 4.3611e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 355/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8000e-04 - val_accuracy: 1.0000 - val_loss: 4.3499e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 356/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8939e-04 - val_accuracy: 1.0000 - val_loss: 4.3015e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 357/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4594e-04 - val_accuracy: 1.0000 - val_loss: 4.2543e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 358/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9782e-04 - val_accuracy: 1.0000 - val_loss: 4.0531e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 359/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4813e-04 - val_accuracy: 1.0000 - val_loss: 4.0208e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 360/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1699e-04 - val_accuracy: 1.0000 - val_loss: 4.3660e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 361/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.2731e-04 - val_accuracy: 1.0000 - val_loss: 4.2195e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 362/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8290e-04 - val_accuracy: 1.0000 - val_loss: 4.0332e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 363/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6056e-04 - val_accuracy: 1.0000 - val_loss: 3.8321e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 364/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1182e-04 - val_accuracy: 1.0000 - val_loss: 3.6855e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 365/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.6494e-04 - val_accuracy: 1.0000 - val_loss: 3.6160e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 366/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2685e-04 - val_accuracy: 1.0000 - val_loss: 3.5440e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 367/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.7068e-05 - val_accuracy: 1.0000 - val_loss: 3.4384e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 368/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5221e-04 - val_accuracy: 1.0000 - val_loss: 3.3863e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 369/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.3334e-04 - val_accuracy: 1.0000 - val_loss: 3.2720e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 370/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5781e-04 - val_accuracy: 1.0000 - val_loss: 3.0907e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 371/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.7490e-05 - val_accuracy: 1.0000 - val_loss: 3.0026e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 372/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0923e-04 - val_accuracy: 1.0000 - val_loss: 2.9405e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 373/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.7896e-04 - val_accuracy: 1.0000 - val_loss: 2.8362e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 374/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1344e-04 - val_accuracy: 1.0000 - val_loss: 2.7306e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 375/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.4385e-05 - val_accuracy: 1.0000 - val_loss: 2.7120e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 376/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.8335e-04 - val_accuracy: 1.0000 - val_loss: 2.5568e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 377/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.1439e-04 - val_accuracy: 1.0000 - val_loss: 3.7402e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 378/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.6777e-04 - val_accuracy: 1.0000 - val_loss: 3.9351e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 379/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.1930e-04 - val_accuracy: 1.0000 - val_loss: 3.6334e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 380/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.4949e-04 - val_accuracy: 1.0000 - val_loss: 5.4451e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 381/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.3628e-04 - val_accuracy: 1.0000 - val_loss: 5.7220e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 382/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.5757e-04 - val_accuracy: 1.0000 - val_loss: 5.5730e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 383/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.2549e-04 - val_accuracy: 1.0000 - val_loss: 5.7406e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 384/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.9754e-04 - val_accuracy: 1.0000 - val_loss: 5.5382e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 385/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.9478e-04 - val_accuracy: 1.0000 - val_loss: 5.1893e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 386/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.6840e-04 - val_accuracy: 1.0000 - val_loss: 4.8267e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 387/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.9211e-04 - val_accuracy: 1.0000 - val_loss: 6.3553e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 388/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.7833e-04 - val_accuracy: 1.0000 - val_loss: 6.3367e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 389/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.3277e-04 - val_accuracy: 1.0000 - val_loss: 5.9592e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 390/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.3242e-04 - val_accuracy: 1.0000 - val_loss: 5.6897e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 391/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.0732e-04 - val_accuracy: 1.0000 - val_loss: 5.4811e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 392/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9833e-04 - val_accuracy: 1.0000 - val_loss: 5.1694e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 393/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.4121e-04 - val_accuracy: 1.0000 - val_loss: 4.7584e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 394/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8207e-04 - val_accuracy: 1.0000 - val_loss: 4.5312e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 395/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8272e-04 - val_accuracy: 1.0000 - val_loss: 4.3834e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 396/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9727e-04 - val_accuracy: 1.0000 - val_loss: 4.2108e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 397/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8721e-04 - val_accuracy: 1.0000 - val_loss: 3.9724e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 398/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.5973e-04 - val_accuracy: 1.0000 - val_loss: 3.7042e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 399/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.3929e-04 - val_accuracy: 1.0000 - val_loss: 3.5241e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 400/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.5690e-04 - val_accuracy: 1.0000 - val_loss: 3.3801e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 401/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3602e-04 - val_accuracy: 1.0000 - val_loss: 3.2758e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 402/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1117e-04 - val_accuracy: 1.0000 - val_loss: 3.1429e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 403/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0455e-04 - val_accuracy: 1.0000 - val_loss: 3.0609e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 404/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2018e-04 - val_accuracy: 1.0000 - val_loss: 2.9579e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 405/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.8192e-04 - val_accuracy: 1.0000 - val_loss: 2.8200e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 406/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2023e-04 - val_accuracy: 1.0000 - val_loss: 2.7865e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 407/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0169e-04 - val_accuracy: 1.0000 - val_loss: 2.7108e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 408/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.6122e-04 - val_accuracy: 1.0000 - val_loss: 2.6425e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 409/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.5925e-05 - val_accuracy: 1.0000 - val_loss: 2.5940e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 410/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.6394e-04 - val_accuracy: 1.0000 - val_loss: 2.5257e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 411/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.3783e-04 - val_accuracy: 1.0000 - val_loss: 2.4388e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 412/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.5144e-05 - val_accuracy: 1.0000 - val_loss: 2.2960e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 413/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0646e-04 - val_accuracy: 1.0000 - val_loss: 2.2488e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 414/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.9772e-05 - val_accuracy: 1.0000 - val_loss: 2.2029e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 415/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.5570e-05 - val_accuracy: 1.0000 - val_loss: 2.0911e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 416/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0407e-04 - val_accuracy: 1.0000 - val_loss: 2.0514e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 417/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.4529e-04 - val_accuracy: 1.0000 - val_loss: 1.9694e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 418/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.6718e-05 - val_accuracy: 1.0000 - val_loss: 1.8937e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 419/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.3356e-04 - val_accuracy: 1.0000 - val_loss: 1.8813e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 420/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.7667e-05 - val_accuracy: 1.0000 - val_loss: 1.8403e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 421/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1873e-04 - val_accuracy: 1.0000 - val_loss: 1.8068e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 422/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.2623e-05 - val_accuracy: 1.0000 - val_loss: 1.9260e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 423/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.3524e-05 - val_accuracy: 1.0000 - val_loss: 1.8887e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 424/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.6020e-05 - val_accuracy: 1.0000 - val_loss: 1.8142e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 425/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.1728e-04 - val_accuracy: 1.0000 - val_loss: 1.7335e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 426/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.2398e-05 - val_accuracy: 1.0000 - val_loss: 1.9558e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 427/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1542e-04 - val_accuracy: 1.0000 - val_loss: 1.8751e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 428/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1225e-04 - val_accuracy: 1.0000 - val_loss: 1.8378e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 429/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.5695e-05 - val_accuracy: 1.0000 - val_loss: 1.8291e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 430/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.3844e-05 - val_accuracy: 1.0000 - val_loss: 1.7422e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 431/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.2367e-04 - val_accuracy: 1.0000 - val_loss: 1.6727e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 432/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.0717e-05 - val_accuracy: 1.0000 - val_loss: 1.5870e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 433/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0245e-04 - val_accuracy: 1.0000 - val_loss: 1.5646e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 434/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.5474e-05 - val_accuracy: 1.0000 - val_loss: 1.5224e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 435/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.4689e-05 - val_accuracy: 1.0000 - val_loss: 1.4678e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 436/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.7050e-05 - val_accuracy: 1.0000 - val_loss: 1.4206e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 437/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.9468e-05 - val_accuracy: 1.0000 - val_loss: 1.4019e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 438/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.5014e-05 - val_accuracy: 1.0000 - val_loss: 1.3759e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 439/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.0037e-04 - val_accuracy: 1.0000 - val_loss: 1.3237e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 440/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.1799e-05 - val_accuracy: 1.0000 - val_loss: 1.3026e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 441/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.0161e-05 - val_accuracy: 1.0000 - val_loss: 1.2616e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 442/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5253e-04 - val_accuracy: 1.0000 - val_loss: 1.2641e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 443/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.0584e-04 - val_accuracy: 1.0000 - val_loss: 1.2356e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 444/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2027e-05 - val_accuracy: 1.0000 - val_loss: 1.2095e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 445/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.1300e-05 - val_accuracy: 1.0000 - val_loss: 1.2269e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 446/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.2943e-05 - val_accuracy: 1.0000 - val_loss: 1.2008e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 447/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.6601e-05 - val_accuracy: 1.0000 - val_loss: 1.2033e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 448/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.6204e-05 - val_accuracy: 1.0000 - val_loss: 1.1685e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 449/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.9655e-05 - val_accuracy: 1.0000 - val_loss: 1.1325e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 450/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.0325e-05 - val_accuracy: 1.0000 - val_loss: 1.1027e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 451/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 1.2478e-04 - val_accuracy: 1.0000 - val_loss: 1.0915e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 452/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.3714e-04 - val_accuracy: 1.0000 - val_loss: 1.9533e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 453/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0135e-04 - val_accuracy: 1.0000 - val_loss: 2.1371e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 454/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0128e-04 - val_accuracy: 1.0000 - val_loss: 2.0179e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 455/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.5169e-05 - val_accuracy: 1.0000 - val_loss: 1.9583e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 456/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.1144e-05 - val_accuracy: 1.0000 - val_loss: 1.8229e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 457/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.2354e-05 - val_accuracy: 1.0000 - val_loss: 1.7745e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 458/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.3722e-05 - val_accuracy: 1.0000 - val_loss: 1.7174e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 459/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1415e-04 - val_accuracy: 1.0000 - val_loss: 1.6304e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 460/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.7066e-05 - val_accuracy: 1.0000 - val_loss: 1.5547e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 461/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.6647e-05 - val_accuracy: 1.0000 - val_loss: 1.4541e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 462/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.2974e-04 - val_accuracy: 1.0000 - val_loss: 1.3746e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 463/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1580e-04 - val_accuracy: 1.0000 - val_loss: 2.1743e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 464/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.1552e-04 - val_accuracy: 1.0000 - val_loss: 2.1172e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 465/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5321e-04 - val_accuracy: 1.0000 - val_loss: 2.0464e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 466/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.8530e-05 - val_accuracy: 1.0000 - val_loss: 2.0154e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 467/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2249e-04 - val_accuracy: 1.0000 - val_loss: 1.8651e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 468/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.3783e-05 - val_accuracy: 1.0000 - val_loss: 1.8726e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 469/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0482e-04 - val_accuracy: 1.0000 - val_loss: 1.7906e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 470/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.6216e-05 - val_accuracy: 1.0000 - val_loss: 1.7000e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 471/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4912e-04 - val_accuracy: 1.0000 - val_loss: 1.6267e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 472/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5940e-04 - val_accuracy: 1.0000 - val_loss: 2.5009e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 473/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4620e-04 - val_accuracy: 1.0000 - val_loss: 2.3507e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 474/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0092e-04 - val_accuracy: 1.0000 - val_loss: 2.1843e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 475/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1261e-04 - val_accuracy: 1.0000 - val_loss: 1.9992e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 476/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.0899e-04 - val_accuracy: 1.0000 - val_loss: 1.8676e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 477/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0471e-04 - val_accuracy: 1.0000 - val_loss: 1.7633e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 478/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.2058e-05 - val_accuracy: 1.0000 - val_loss: 1.6652e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 479/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.0625e-04 - val_accuracy: 1.0000 - val_loss: 1.5013e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 480/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1040e-04 - val_accuracy: 1.0000 - val_loss: 1.4429e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 481/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.9188e-05 - val_accuracy: 1.0000 - val_loss: 1.3995e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 482/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.5021e-05 - val_accuracy: 1.0000 - val_loss: 1.3411e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 483/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.7804e-05 - val_accuracy: 1.0000 - val_loss: 1.2728e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 484/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.7474e-05 - val_accuracy: 1.0000 - val_loss: 1.1896e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 485/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.9062e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 486/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3985e-04 - val_accuracy: 1.0000 - val_loss: 1.1561e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 487/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2030e-04 - val_accuracy: 1.0000 - val_loss: 2.6648e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 488/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3357e-04 - val_accuracy: 1.0000 - val_loss: 2.1110e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 489/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1878e-04 - val_accuracy: 1.0000 - val_loss: 1.8304e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 490/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1699e-04 - val_accuracy: 1.0000 - val_loss: 1.7136e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 491/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.4783e-04 - val_accuracy: 1.0000 - val_loss: 1.6031e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 492/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.5288e-04 - val_accuracy: 1.0000 - val_loss: 1.5460e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 493/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2408e-04 - val_accuracy: 1.0000 - val_loss: 1.3721e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 494/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.9624e-05 - val_accuracy: 1.0000 - val_loss: 1.3138e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 495/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.1832e-05 - val_accuracy: 1.0000 - val_loss: 1.2691e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 496/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.1498e-04 - val_accuracy: 1.0000 - val_loss: 1.2045e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 497/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.6069e-05 - val_accuracy: 1.0000 - val_loss: 1.1896e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 498/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.0160e-05 - val_accuracy: 1.0000 - val_loss: 1.1139e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 499/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.4521e-05 - val_accuracy: 1.0000 - val_loss: 1.0754e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 500/500\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.8157e-05 - val_accuracy: 1.0000 - val_loss: 1.0344e-06 - learning_rate: 1.0000e-04\n",
      "[DCNN_2L] Training done!, took 263.4746916294098s\n",
      "[DCNN_2L] Predicting\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "[DCNN_2L] Prediction done!\n",
      "[DCNN_2L] Predicting\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[DCNN_2L] Prediction done!\n",
      "[Main] Problem: NATOPS\n",
      "   accuracy train/val/test/test2\n",
      "0  0.986667                 test\n",
      "1  0.986667                test2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.tools import create_directory\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "def fit_classifier(all_labels, X_train, y_train, X_val=None, y_val=None, epochs=10, batch_size=16):\n",
    "    nb_classes = len(np.unique(all_labels))\n",
    "    # Create Classifier --------------------------------------------------------\n",
    "    if classifier_name == \"FCN\" or classifier_name == \"ResNet\":\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    elif classifier_name == \"lstm_dcnn\" or classifier_name == \"MLSTM_FCN\":\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    else:\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "    # Call Classifier ----------------------------------------------------------\n",
    "    classifier = create_classifier(classifier_name, input_shape, nb_classes, verbose=True)\n",
    "    # Train Classifier ----------------------------------------------------------\n",
    "    if X_val is None:\n",
    "        classifier.fit(X_train, y_train, None, None, epochs, batch_size)\n",
    "    else:\n",
    "        classifier.fit(X_train, y_train, X_val, y_val, epochs, batch_size)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def create_classifier(classifier_name, input_shape, nb_classes, verbose=False):\n",
    "\n",
    "    # Networks ------------------------------------------------------------------------------\n",
    "    if classifier_name == \"T_CNN\":\n",
    "        from classifiers import T_CNN\n",
    "        return T_CNN.Classifier_T_CNN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"S_CNN\":\n",
    "        from classifiers import S_CNN\n",
    "        return S_CNN.Classifier_S_CNN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"ST_CNN\":\n",
    "        from classifiers import ST_CNN\n",
    "        return ST_CNN.Classifier_ST_CNN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "\n",
    "    if classifier_name == \"DCNN_2L\":\n",
    "        from classifiers import DCNN_2L\n",
    "        return DCNN_2L.Classifier_DCNN_2L(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"DCNN_3L\":\n",
    "        from classifiers import DCNN_3L\n",
    "        return DCNN_3L.Classifier_DCNN_3L(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"DCNN_4L\":\n",
    "        from classifiers import DCNN_4L\n",
    "        return DCNN_4L.Classifier_DCNN_4L(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------------------\n",
    "    # Component Analysis -----------------------------------------------------------------------------------------------\n",
    "    if classifier_name == \"FCN\":\n",
    "        from classifiers import FCN\n",
    "        return FCN.Classifier_FCN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"D_FCN\":\n",
    "        from classifiers import D_FCN\n",
    "        return D_FCN.Classifier_D_FCN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "\n",
    "    if classifier_name == \"ResNet\":\n",
    "        from classifiers import ResNet\n",
    "        return ResNet.Classifier_ResNet(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"D_ResNet\":\n",
    "        from classifiers import D_ResNet\n",
    "        return D_ResNet.Classifier_D_ResNet(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "\n",
    "    if classifier_name == \"MC_CNN\":\n",
    "        from classifiers import MC_CNN\n",
    "        return MC_CNN.Classifier_MC_CNN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == \"MLSTM_FCN\":\n",
    "        from classifiers import MLSTM_FCN\n",
    "        return MLSTM_FCN.Classifier_MLSTM_FCN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "    elif classifier_name == \"lstm_dcnn\":\n",
    "        from classifiers import lstm_dcnn\n",
    "        return lstm_dcnn.Classifier_LSTM_DCNN(sub_output_directory, input_shape, nb_classes, verbose)\n",
    "\n",
    "\n",
    "def s_length(train_df, test_df):\n",
    "    train_lengths = train_df.applymap(lambda x: len(x)).values\n",
    "    test_lengths = test_df.applymap(lambda x: len(x)).values\n",
    "\n",
    "    train_vert_diffs = np.abs(train_lengths - np.expand_dims(train_lengths[0, :], 0))\n",
    "\n",
    "    if np.sum(train_vert_diffs) > 0:  # if any column (dimension) has varying length across samples\n",
    "        train_max_seq_len = int(np.max(train_lengths[:, 0]))\n",
    "        test_max_seq_len = int(np.max(test_lengths[:, 0]))\n",
    "        max_seq_len = np.max([train_max_seq_len, test_max_seq_len])\n",
    "    else:\n",
    "        max_seq_len = train_lengths[0, 0]\n",
    "    return max_seq_len\n",
    "# Problem Setting -----------------------------------------------------------------------------------------------------\n",
    "ALL_Results = pd.DataFrame()\n",
    "ALL_Results_list = []\n",
    "problem_index = 0\n",
    "data_path = os.getcwd() + '/multivariate_ts/'\n",
    "# Hyper-Parameter Setting ----------------------------------------------------------------------------------------------\n",
    "classifier_name = \"DCNN_2L\"  # Choose the classifier name from aforementioned List\n",
    "epochs = 500\n",
    "Resample = 1  # Set to '1' for default Train and Test Sets, and '30' for running on all resampling\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for problem in os.listdir(data_path):\n",
    "    # Load Data --------------------------------------------------------------------------------------------------------\n",
    "    output_directory = os.getcwd() + '/Results_'\n",
    "    output_directory = output_directory + classifier_name + '/' + problem + '/'\n",
    "    create_directory(output_directory)\n",
    "    print(\"[Main] Problem: {}\".format(problem))\n",
    "    itr_result = [problem]\n",
    "    # load --------------------------------------------------------------------------\n",
    "    # set data folder\n",
    "    X_train, Y_train = load_classification(\"ArticularyWordRecognition\",  split=\"train\")\n",
    "    X_test, Y_test = load_classification(\"ArticularyWordRecognition\",  split=\"test\")\n",
    "\n",
    "    all_data = np.vstack((X_train, X_test))\n",
    "    all_labels = np.hstack((Y_train, Y_test))\n",
    "    all_indices = np.arange(len(all_data))\n",
    "\n",
    "    sub_output_directory = output_directory + str(1) + '/'\n",
    "    create_directory(sub_output_directory)\n",
    "    # Default Train and Test Set\n",
    "    x_train = X_train\n",
    "    x_test = X_test\n",
    "    y_train = Y_train\n",
    "    y_test = Y_test\n",
    "    \n",
    "    # Making Consistent with Keras Output -------------------------------------------------\n",
    "    all_labels_new = np.concatenate((y_train, y_test), axis=0)\n",
    "    print(\"[Main] All labels: {}\".format(np.unique(all_labels_new)))\n",
    "    tmp = pd.get_dummies(all_labels_new).values\n",
    "    y_train = tmp[:len(y_train)]\n",
    "    y_test = tmp[len(y_train):]\n",
    "\n",
    "    # Making Consistent with Keras Input ---------------------------------------------------\n",
    "    if classifier_name == \"FCN\" or classifier_name == \"ResNet\" or classifier_name == \"MLSTM_FCN\":\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[2], x_train.shape[1])\n",
    "        x_test = x_test.reshape(x_test.shape[0], x_test.shape[2], x_test.shape[1])\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "    # classifier-----------------------------------------------------------------\n",
    "    # Dynamic Batch-size base on Data\n",
    "    if problem == 'EigenWorms' or problem == 'DuckDuck':\n",
    "        batch_size = 1\n",
    "    else:\n",
    "        # batch_size = np.ceil(x_train.shape[0] / (8 * (np.max(y_train.shape[1]) + 1)))\n",
    "        batch_size = 8\n",
    "        \n",
    "    val_index = np.random.randint(0, np.int(x_train.shape[0]), np.int(x_train.shape[0] / 10), dtype=int)\n",
    "    x_val = x_train[val_index, :]\n",
    "    y_val = y_train[val_index, :]\n",
    "\n",
    "    classifier = fit_classifier(all_labels_new, x_train, y_train, x_val, y_val, epochs, batch_size)\n",
    "    metrics_test, conf_mat = classifier.predict(x_test, y_test, best=True)\n",
    "    metrics_test2, conf_mat2 = classifier.predict(x_test, y_test, best=False)\n",
    "\n",
    "    metrics_test['train/val/test/test2'] = 'test'\n",
    "    metrics_test2['train/val/test/test2'] = 'test2'\n",
    "    metrics = pd.concat([metrics_test, metrics_test2]).reset_index(drop=True)\n",
    "\n",
    "    print(\"[Main] Problem: {}\".format(problem))\n",
    "    print(metrics.head())\n",
    "\n",
    "    metrics.to_csv(sub_output_directory + 'classification_metrics.csv')\n",
    "    np.savetxt(sub_output_directory + 'confusion_matrix.csv', conf_mat, delimiter=\",\")\n",
    "    itr_result.append(metrics.accuracy[0])\n",
    "    itr_result.append(metrics.accuracy[1])\n",
    "    sub_output_directory = []\n",
    "\n",
    "    if len(ALL_Results_list) == 0:\n",
    "        ALL_Results_list = np.hstack((ALL_Results_list, itr_result))\n",
    "    else:\n",
    "        ALL_Results_list = np.vstack((ALL_Results_list, itr_result))\n",
    "\n",
    "    problem_index = problem_index + 1\n",
    "\n",
    "ALL_Results = pd.DataFrame(ALL_Results_list)\n",
    "ALL_Results.to_csv(os.getcwd() + '/Results_' + classifier_name + '/'+'All_results1.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
